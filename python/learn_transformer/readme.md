## 

### 官方有一个使用TransformerEncoder一个例子，但是应该是版本不对，在torchtext那里就报错了，所以忽略此处
[地址](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)，也是transformer_tutorial.py例子。

### 也可以瞅瞅[tutorial](https://github.com/pytorch/examples/tree/master/word_language_model)，不过没看

### 也可以看看[TransformDemo](git@github.com:Kenneth111/TransformerDemo.git)
但是这个我只看懂了positional embedding前面要接一个embedding，其他部分就没细看了。

